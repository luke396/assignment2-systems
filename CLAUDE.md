# Project Guidelines

## Project Overview

**CS336 Spring 2025 Assignment 2: Systems** - A course assignment focused on GPU performance analysis, optimization, and distributed training for Transformer language models.

### Learning Objectives

- GPU memory profiling and optimization
- Mixed-precision training (FP16/BF16)
- CUDA kernel analysis with Nsight Systems
- Performance benchmarking

### Project Context

This is a **course assignment project** focused on learning:

- The primary goal is educational exploration and understanding.
- Test coverage is intentionally incomplete and **should not be added by students**.
- Focus on benchmarking, profiling, and performance analysis rather than production-ready code.

## Project Structure

```
.
├── cs336_systems/          # Main module (benchmark, profiling code)
│   ├── benchmark.py        # Benchmark runner with profiling modes
│   ├── configs.py          # Model configurations
│   └── nvtx_model.py       # NVTX-annotated model wrapper
├── cs336-basics/           # Assignment 1 implementation (git submodule)
├── scripts/                # Analysis and automation scripts
│   ├── run_benchmarks.py   # Benchmark orchestration
│   ├── analyze_*.py        # Result analysis scripts
│   └── generate_docs.py    # Documentation generator
├── docs/                   # Documentation system (see below)
├── output/                 # Benchmark results and profiling data
└── tests/                  # Test files (provided by course)
```

## Environment

- Use `uv` for environment management.
- Unless otherwise specified, assume code runs on a single A800-80G GPU server.
- Default assumption: the local machine does not have the full dataset or a comparable high-VRAM GPU.

## Code Quality

- For modified code only, `ruff check <paths>` must pass with no warnings.
- For modified code only, `ty check <paths>` must pass with no type errors.
- Do not suppress linter/type checker errors (e.g., `# noqa`, `# type: ignore`) unless it is best practice; if suppression is necessary, add a comment explaining the reason.

## Workflow

- Ask for confirmation before modifying code outside the current discussion scope.
- After each code change, self-review and simplify, then run targeted `ruff`/`ty` checks and ensure they pass.

## Version Control

- Use separate branches or `git worktree` for AI coding changes, based on the task.
- Commit message format: `type: description`
  - `bench:` - benchmark related changes
  - `docs:` - documentation
  - `chore:` - miscellaneous (config, deps, etc.)
  - `fix:` - bug fixes
  - `feat:` - new features (non-benchmark)

## Communication

- Align response language to the user's input language.

## Documentation System

The project uses an automated documentation generation system with Jinja2 templates.

### Directory Structure

```
docs/
├── README.md                    # Final assembled document (generated)
├── images/                      # Image assets
├── sections/                    # Document fragments (generated by analysis scripts)
│   ├── benchmarking.md
│   ├── nsys-profile.md
│   ├── mixed-precision.md
│   ├── mixed_precision_*.md
│   └── memory-profile-(a~d).md
└── templates/                   # Jinja2 template files
    ├── main.md.j2               # Main template
    ├── benchmarking_mixed_precision.md.j2
    └── benchmarking_memory.md.j2
```

### Generation Pipeline

1. **Raw data** (`output/`) → **Analysis scripts** → **Document fragments** (`docs/sections/`)
2. **Templates** (`docs/templates/`) + **Fragments** → **Jinja2 render** → **Final document** (`docs/README.md`)

### Analysis Scripts (`scripts/`)

| Script                        | Input                         | Output                |
| ----------------------------- | ----------------------------- | --------------------- |
| `analyze_basic_benchmarks.py` | `benchmark_results__{tag}.md` | `benchmarking.md`     |
| `analyze_nsys_profile.py`     | `*.nsys-rep`                  | `nsys-profile.md`     |
| `analyze_mixed_precision.py`  | `*.nsys-rep`                  | `mixed-precision.md`  |
| `analyze_memory_snapshot.py`  | `*.snap`                      | `memory-profile-*.md` |

### Usage

```bash
# Regenerate all fragments and assemble final document
python scripts/generate_docs.py --regenerate-all

# Assemble final document from existing fragments only
python scripts/generate_docs.py

# Regenerate specific fragment
python scripts/analyze_memory_snapshot.py --mode baseline --run-tag <tag>
```

### Guidelines

- **Never edit `docs/README.md` directly** - it is auto-generated and will be overwritten.
- **Edit templates** (`docs/templates/*.j2`) to change document structure.
- **Edit analysis scripts** (`scripts/analyze_*.py`) to change fragment content generation.
- **Manually edit fragments** (`docs/sections/*.md`) only for quick iterations; prefer updating analysis scripts for permanent changes.
